# üåç Whisper Multilingual Model Configuration

## üìä Model Comparison

| Model | Size | Languages | Use Case |
|-------|------|-----------|----------|
| ggml-base.bin | 33MB | All languages | Primary model - supports Spanish, English, etc. |
| ggml-base.en.bin | 142MB | English only | Fallback if base model fails |

## ‚úÖ Implementation

### Dynamic Model Selection

Both Netlify Functions now implement intelligent model selection:

```javascript
// Set model paths - base (multilingual) as primary, base.en as fallback
const MODEL_PATH_BASE = path.join(process.cwd(), 'public', 'models', 'ggml-base.bin');
const MODEL_PATH_EN = path.join(process.cwd(), 'public', 'models', 'ggml-base.en.bin');

// Check which model exists and use appropriately
const baseExists = fs.existsSync(MODEL_PATH_BASE);
const enExists = fs.existsSync(MODEL_PATH_EN);

// Use base (multilingual) if available, fallback to base.en
const MODEL_PATH = baseExists ? MODEL_PATH_BASE : MODEL_PATH_EN;
```

### Benefits

1. **Multilingual Support**: Primary model supports all languages including Spanish for medical terms
2. **Automatic Fallback**: If base model is missing/corrupted, uses English model
3. **Dynamic Reporting**: Response indicates which model was used
4. **No Download Required**: Uses pre-existing models in `public/models/`

### Model Details

- **Base Model (33MB)**: Smaller file size but supports all languages
- **Base.en Model (142MB)**: Larger but optimized for English only
- Both models are suitable for medical transcription

### Usage

The functions will automatically:
1. Check if `ggml-base.bin` exists
2. Use it for multilingual transcription if available
3. Fall back to `ggml-base.en.bin` if base is missing
4. Report which model was used in the response

Example response:
```json
{
  "model_used": "nodejs-whisper base (multilingual) (Netlify Function)"
}
```

## üîß Configuration

No configuration needed - the system automatically selects the best available model. To force a specific model, you can:

1. Remove the model you don't want to use from `public/models/`
2. Or set environment variable `WHISPER_MODEL` in the microservice

## üìù Notes

- The 33MB base model is surprisingly efficient despite its smaller size
- It provides good accuracy for medical terminology in multiple languages
- The larger base.en model serves as a reliable fallback
- Both models are committed to the repository for reliability
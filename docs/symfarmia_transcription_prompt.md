# ğŸ™ï¸ PROMPT COMPLETO: MigraciÃ³n TranscripciÃ³n Frontend â†’ Backend API

## ğŸ¯ **OBJETIVO PRINCIPAL**
Crear endpoint `/api/transcription` en Next.js que actÃºe como proxy entre frontend y microservicio SusurroTest, eliminando acceso directo desde cliente.

## ğŸš« **PROBLEMA ACTUAL**
- Frontend llama directamente a `http://localhost:3001` (SusurroTest)
- ExposiciÃ³n de URL de microservicio en cliente
- Falta capa de abstracciÃ³n y validaciÃ³n
- Sin manejo centralizado de FFmpeg/conversiÃ³n

## âœ… **SOLUCIÃ“N REQUERIDA**
Crear endpoint Next.js que:
1. Reciba audio blob desde frontend
2. Procese/valide archivo
3. Transforme a formato correcto (WAV/FFmpeg si necesario)
4. EnvÃ­e al microservicio SusurroTest
5. Retorne respuesta unificada

---

## ğŸ“‚ **ARCHIVOS A CREAR/MODIFICAR**

### 1. **app/api/transcription/route.ts** â­ (NUEVO - PRINCIPAL)
```typescript
/**
 * ğŸ™ï¸ Endpoint de TranscripciÃ³n - Proxy a SusurroTest
 * Maneja audio desde frontend, procesa y envÃ­a a microservicio
 */

import { NextRequest, NextResponse } from 'next/server';
import { headers } from 'next/headers';

// ConfiguraciÃ³n del microservicio
const SUSURRO_CONFIG = {
  baseUrl: process.env.SUSURRO_SERVICE_URL || 'http://localhost:3001',
  endpoint: '/api/transcribe-upload',
  timeout: 30000, // 30 segundos
  maxFileSize: 10 * 1024 * 1024, // 10MB
  allowedTypes: ['audio/wav', 'audio/webm', 'audio/mp3', 'audio/m4a']
};

export async function POST(request: NextRequest) {
  const startTime = Date.now();
  
  try {
    // ğŸ“ Logs con emojis (mantener estilo existente)
    console.log('ğŸ™ï¸ [Transcription API] Iniciando procesamiento...');
    
    // ğŸ“‹ Validar Content-Type
    const contentType = request.headers.get('content-type');
    if (!contentType?.includes('multipart/form-data')) {
      return NextResponse.json(
        { success: false, error: 'ğŸš« Content-Type debe ser multipart/form-data' },
        { status: 400 }
      );
    }

    // ğŸ“ Extraer archivo del FormData
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;
    
    if (!audioFile) {
      console.log('âŒ [Transcription API] No se encontrÃ³ archivo de audio');
      return NextResponse.json(
        { success: false, error: 'ğŸ¤ No se encontrÃ³ archivo de audio' },
        { status: 400 }
      );
    }

    // ğŸ” Validaciones de archivo
    if (audioFile.size > SUSURRO_CONFIG.maxFileSize) {
      return NextResponse.json(
        { success: false, error: `ğŸ“ Archivo muy grande. MÃ¡ximo: ${SUSURRO_CONFIG.maxFileSize / 1024 / 1024}MB` },
        { status: 413 }
      );
    }

    console.log(`ğŸµ [Transcription API] Archivo recibido: ${audioFile.name} (${audioFile.size} bytes)`);

    // ğŸ”„ Convertir a formato compatible si es necesario
    let processedFile = audioFile;
    if (!SUSURRO_CONFIG.allowedTypes.includes(audioFile.type)) {
      console.log(`ğŸ”„ [Transcription API] Convirtiendo ${audioFile.type} a WAV...`);
      processedFile = await convertToWAV(audioFile);
    }

    // ğŸŒ Preparar FormData para microservicio
    const susurroFormData = new FormData();
    susurroFormData.append('audio', processedFile);

    // ğŸ“¡ Enviar a SusurroTest
    console.log('ğŸ“¡ [Transcription API] Enviando a SusurroTest...');
    
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), SUSURRO_CONFIG.timeout);

    const response = await fetch(`${SUSURRO_CONFIG.baseUrl}${SUSURRO_CONFIG.endpoint}`, {
      method: 'POST',
      body: susurroFormData,
      signal: controller.signal,
      headers: {
        // No incluir Content-Type, fetch lo manejarÃ¡ automÃ¡ticamente con FormData
      }
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      throw new Error(`SusurroTest error: ${response.status} ${response.statusText}`);
    }

    const result = await response.json();
    const processingTime = Date.now() - startTime;

    console.log(`âœ… [Transcription API] Completado en ${processingTime}ms`);
    console.log(`ğŸ“ [Transcription API] TranscripciÃ³n: "${result.transcript}"`);

    // ğŸ“¤ Respuesta unificada
    return NextResponse.json({
      success: true,
      transcript: result.transcript || '',
      confidence: result.confidence || 0,
      processing_time_ms: processingTime,
      source: 'susurro-microservice',
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    const processingTime = Date.now() - startTime;
    console.error(`âŒ [Transcription API] Error despuÃ©s de ${processingTime}ms:`, error);

    // ğŸ” Manejo especÃ­fico de errores
    let errorMessage = 'Error interno del servidor';
    let statusCode = 500;

    if (error.name === 'AbortError') {
      errorMessage = 'â±ï¸ Timeout: El procesamiento tardÃ³ demasiado';
      statusCode = 408;
    } else if (error.message.includes('SusurroTest')) {
      errorMessage = 'ğŸ”´ Microservicio SusurroTest no disponible';
      statusCode = 503;
    } else if (error.message.includes('fetch')) {
      errorMessage = 'ğŸŒ Error de conectividad con SusurroTest';
      statusCode = 502;
    }

    return NextResponse.json(
      { 
        success: false, 
        error: errorMessage,
        processing_time_ms: processingTime,
        timestamp: new Date().toISOString()
      },
      { status: statusCode }
    );
  }
}

// ğŸ”„ FunciÃ³n para convertir audio a WAV (si es necesario)
async function convertToWAV(audioFile: File): Promise<File> {
  // Implementar conversiÃ³n usando FFmpeg o Web Audio API
  // Por ahora, retornar el archivo original
  console.log('âš ï¸ [Transcription API] ConversiÃ³n WAV no implementada, usando archivo original');
  return audioFile;
}

export async function GET() {
  return NextResponse.json({
    message: 'ğŸ™ï¸ Transcription API - Endpoint para procesamiento de audio',
    methods: ['POST'],
    maxFileSize: `${SUSURRO_CONFIG.maxFileSize / 1024 / 1024}MB`,
    allowedTypes: SUSURRO_CONFIG.allowedTypes,
    microservice: SUSURRO_CONFIG.baseUrl
  });
}
```

### 2. **hooks/useTranscription.ts** ğŸ”„ (MODIFICAR)
```typescript
// ğŸ”„ Cambiar SusurroClient para apuntar al endpoint local
class SusurroClient {
  static async transcribeAudio(audioBlob: Blob): Promise<TranscriptionResult> {
    const formData = new FormData();
    formData.append('audio', audioBlob, 'recording.wav');
    
    // âœ… CAMBIO PRINCIPAL: Apuntar al endpoint local en lugar del microservicio
    const response = await fetch('/api/transcription', {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }
    
    return await response.json();
  }
  
  static async healthCheck(): Promise<{ status: string }> {
    // Mantener health check al microservicio directo para validaciÃ³n
    const response = await fetch('/api/transcription');
    return await response.json();
  }
}
```

### 3. **lib/ffmpeg.ts** ğŸ†• (OPCIONAL - FUTURO)
```typescript
/**
 * ğŸµ FFmpeg utilities para conversiÃ³n de audio
 * Para implementaciÃ³n futura de conversiÃ³n en servidor
 */

// Placeholder para futuras implementaciones de FFmpeg
export async function convertAudioToWAV(inputBuffer: ArrayBuffer): Promise<ArrayBuffer> {
  // Implementar usando @ffmpeg/ffmpeg o similar
  throw new Error('FFmpeg conversion not implemented yet');
}
```

### 4. **middleware.ts** ğŸ”„ (MODIFICAR SI EXISTE)
```typescript
// AÃ±adir validaciones especÃ­ficas para /api/transcription
export function middleware(request: NextRequest) {
  // Validaciones de rate limiting para transcripciÃ³n si es necesario
  if (request.nextUrl.pathname.startsWith('/api/transcription')) {
    // Implementar rate limiting, authentication, etc.
  }
}
```

---

## ğŸ”§ **VARIABLES DE ENTORNO**

### **.env.local** ğŸ”„ (MODIFICAR)
```bash
# Microservicio SusurroTest (solo para backend)
SUSURRO_SERVICE_URL=http://localhost:3001

# ConfiguraciÃ³n de transcripciÃ³n
TRANSCRIPTION_MAX_FILE_SIZE=10485760  # 10MB
TRANSCRIPTION_TIMEOUT=30000           # 30 segundos
```

### **.env.example** ğŸ”„ (ACTUALIZAR)
```bash
# AÃ±adir documentaciÃ³n de nuevas variables
SUSURRO_SERVICE_URL=http://localhost:3001
TRANSCRIPTION_MAX_FILE_SIZE=10485760
TRANSCRIPTION_TIMEOUT=30000
```

---

## ğŸ§ª **TESTING**

### **Pruebas a realizar:**
1. **Endpoint bÃ¡sico**: `curl -X GET http://localhost:3000/api/transcription`
2. **Upload de audio**: Test con archivo WAV/WebM pequeÃ±o
3. **ValidaciÃ³n de tamaÃ±o**: Test con archivo grande (>10MB)
4. **Timeout**: Test con microservicio desconectado
5. **Tipos de archivo**: Test con MP3, M4A, etc.

### **Comando de prueba manual:**
```bash
# Test bÃ¡sico del endpoint
curl -X POST http://localhost:3000/api/transcription \
  -F "audio=@test-audio.wav" \
  -H "Accept: application/json"
```

---

## ğŸ“‹ **VALIDATION CHECKLIST**

- [ ] âœ… **Endpoint creado**: `/api/transcription/route.ts` existe
- [ ] ğŸ”„ **Hook actualizado**: useTranscription apunta a endpoint local
- [ ] ğŸš« **Sin acceso directo**: Frontend no llama a `localhost:3001`
- [ ] ğŸ“ **Logging consistente**: Emojis y formato mantenido
- [ ] ğŸ” **Validaciones**: TamaÃ±o, tipo, timeout implementados
- [ ] ğŸŒ **Error handling**: Manejo de fallos del microservicio
- [ ] âš¡ **Performance**: Respuesta en <5 segundos tÃ­pico
- [ ] ğŸ§ª **Testing**: Pruebas bÃ¡sicas completadas

---

## ğŸš€ **EJECUCIÃ“N**

### **Orden de implementaciÃ³n:**
1. **Crear** `app/api/transcription/route.ts`
2. **Modificar** `hooks/useTranscription.ts` (SusurroClient)
3. **Actualizar** variables de entorno
4. **Probar** endpoint con archivo de audio
5. **Validar** que frontend funciona sin acceso directo
6. **Documentar** cambios en README

### **Comandos para probar:**
```bash
# 1. Iniciar microservicio
cd microservices/susurro-test && npm start

# 2. Iniciar Next.js
npm run dev

# 3. Probar endpoint
curl -X GET http://localhost:3000/api/transcription

# 4. Probar transcripciÃ³n
# (usar interfaz web o curl con archivo)
```

---

## ğŸ“– **DOCUMENTACIÃ“N ADICIONAL**

### **README.md actualizaciÃ³n:**
```markdown
## ğŸ™ï¸ TranscripciÃ³n de Audio

La transcripciÃ³n utiliza un endpoint proxy `/api/transcription` que:
- Valida archivos de audio del frontend
- Procesa y envÃ­a al microservicio SusurroTest
- Retorna respuesta unificada
- Maneja errores y timeouts

### Uso desde frontend:
\`\`\`typescript
const formData = new FormData();
formData.append('audio', audioBlob);

const response = await fetch('/api/transcription', {
  method: 'POST',
  body: formData
});
\`\`\`
```

---

## ğŸ¯ **RESULTADO ESPERADO**

**Antes:** `Frontend â†’ http://localhost:3001 (directo)`
**DespuÃ©s:** `Frontend â†’ /api/transcription â†’ SusurroTest`

âœ… **Seguridad mejorada**: No exposiciÃ³n de URLs internas
âœ… **ValidaciÃ³n centralizada**: Control en servidor
âœ… **Error handling robusto**: Manejo de fallos del microservicio
âœ… **Logging unificado**: Consistente con estilo existente
âœ… **Escalabilidad**: FÃ¡cil cambio de microservicio backend

---

*ğŸ©º **NOTA MÃ‰DICA**: Esta migraciÃ³n mejora la seguridad y confiabilidad del sistema de transcripciÃ³n mÃ©dica, critical para entornos clÃ­nicos donde la disponibilidad es vital.*
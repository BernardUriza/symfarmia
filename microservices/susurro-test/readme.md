# ğŸ™ï¸ Whisper Transcription Microservice

> **Microservicio profesional de transcripciÃ³n de audio** basado en OpenAI Whisper, diseÃ±ado para integrarse sin fricciÃ³n en cualquier arquitectura moderna.

[![Node.js](https://img.shields.io/badge/node-%3E%3D14.0-brightgreen)](https://nodejs.org)
[![Express](https://img.shields.io/badge/express-4.18-blue)](https://expressjs.com)
[![Whisper](https://img.shields.io/badge/whisper-nodejs--whisper-orange)](https://github.com/nodejs-whisper/nodejs-whisper)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

## ğŸš€ Â¿Por quÃ© este microservicio?

Este no es solo otro servidor de transcripciÃ³n. Es un **microservicio production-ready** diseÃ±ado desde cero para:

- ğŸ”Œ **IntegraciÃ³n Plug & Play**: Funciona con Next.js, React, Vue, Angular o cualquier stack
- ğŸ—ï¸ **Arquitectura de Microservicios**: Perfecto para monorepos y arquitecturas distribuidas
- ğŸ› ï¸ **AutoconfiguraciÃ³n**: Scripts inteligentes que detectan y configuran dependencias
- ğŸ“¦ **Zero Config**: Funciona out-of-the-box con configuraciÃ³n sensata
- ğŸ”„ **API RESTful**: Endpoints claros y bien documentados
- ğŸ³ **Docker Ready**: Preparado para containerizaciÃ³n y orquestaciÃ³n

## ğŸ“‹ CaracterÃ­sticas

- âœ… TranscripciÃ³n de audio local con Whisper C++
- âœ… Soporte para mÃºltiples formatos de audio vÃ­a FFmpeg
- âœ… API REST completa con health checks
- âœ… GestiÃ³n automÃ¡tica de dependencias
- âœ… Scripts de integraciÃ³n para frameworks populares
- âœ… Modo desarrollo con hot-reload
- âœ… Logs estructurados con timestamps

## ğŸ›ï¸ Arquitectura del Microservicio

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client App    â”‚â”€â”€â”€â”€â–¶â”‚  Whisper Î¼Serviceâ”‚â”€â”€â”€â”€â–¶â”‚  Whisper C++   â”‚
â”‚ (Next.js, etc)  â”‚â—€â”€â”€â”€â”€â”‚   (Express.js)   â”‚â—€â”€â”€â”€â”€â”‚    Binary       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   FFmpeg    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš¦ Inicio RÃ¡pido

### Como servicio standalone

```bash
# Clonar y configurar
git clone https://github.com/tu-usuario/whisper-transcription-microservice.git
cd whisper-transcription-microservice

# InstalaciÃ³n automÃ¡tica completa
npm run setup

# Iniciar el microservicio
npm start
```

### Como parte de tu arquitectura

```bash
# Desde tu proyecto principal
curl -sSL https://raw.githubusercontent.com/tu-usuario/whisper-transcription-microservice/main/integrate-nextjs.sh | bash
```

## ğŸ¤– AutomatizaciÃ³n de la IntegraciÃ³n

Para facilitar el proceso, hemos creado un script que se encarga de clonar el repositorio del microservicio, crear la carpeta correspondiente dentro de la estructura de tu proyecto, y configurar todo automÃ¡ticamente.

### Pasos para usar el script

1. **OpciÃ³n 1: EjecuciÃ³n directa desde internet**
   ```bash
   curl -sSL https://raw.githubusercontent.com/tu-usuario/whisper-transcription-microservice/main/integrate-nextjs.sh | bash
   ```

2. **OpciÃ³n 2: Descarga y ejecuciÃ³n local**
   ```bash
   # Descargar el script
   wget https://raw.githubusercontent.com/tu-usuario/whisper-transcription-microservice/main/integrate-nextjs.sh
   
   # Dar permisos de ejecuciÃ³n
   chmod +x integrate-nextjs.sh
   
   # Ejecutar con opciones personalizadas
   ./integrate-nextjs.sh --service-name mi-whisper --repo-url https://github.com/mi-fork/whisper
   ```

### Â¿QuÃ© hace el script?

- âœ… Detecta si estÃ¡s en un proyecto Next.js
- âœ… Crea la estructura de monorepo si no existe
- âœ… Clona el microservicio en la ubicaciÃ³n correcta
- âœ… Instala dependencias del sistema (ffmpeg, cmake, etc.)
- âœ… Configura el microservicio automÃ¡ticamente
- âœ… Actualiza tu package.json con scripts Ãºtiles
- âœ… Crea un cliente JavaScript listo para usar
- âœ… Genera un componente React de ejemplo
- âœ… Configura variables de entorno

### PersonalizaciÃ³n del script

```bash
# Ver opciones disponibles
./integrate-nextjs.sh --help

# Integrar con nombre personalizado
./integrate-nextjs.sh --service-name audio-service

# Usar un fork del repositorio
./integrate-nextjs.sh --repo-url https://github.com/mi-usuario/mi-fork
```

## ğŸ”§ Requisitos del Sistema

### MÃ­nimos
- Node.js 14+ 
- 4GB RAM
- 2 CPU cores

### Recomendados para producciÃ³n
- Node.js 18+
- 8GB RAM
- 4+ CPU cores
- Ubuntu 20.04+ / macOS 12+

### Dependencias del sistema
```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y ffmpeg cmake build-essential

# macOS
brew install ffmpeg cmake
```

## ğŸ“¡ API Reference

### Endpoints

#### `GET /api/health`
Health check del microservicio

**Response:**
```json
{
  "status": "healthy",
  "service": "whisper-transcription-microservice",
  "version": "1.0.0",
  "uptime": 3600
}
```

#### `POST /api/transcribe-upload`
Transcribe archivo subido

**Request:**
- Method: `POST`
- Content-Type: `multipart/form-data`
- Body: `audio` (file)

**Response:**
```json
{
  "success": true,
  "transcript": "Texto transcrito...",
  "processing_time_ms": 1234,
  "model_used": "base",
  "timestamp": "2025-01-12T10:00:00.000Z"
}
```

#### `POST /api/transcribe-server-file`
Transcribe archivo existente en el servidor

**Request:**
```json
{
  "filename": "audio.wav"
}
```

#### `GET /api/files`
Lista archivos disponibles para transcripciÃ³n

## ğŸ—ï¸ IntegraciÃ³n en Arquitecturas Modernas

### Next.js App Router

```typescript
// app/lib/whisper-service.ts
export class WhisperService {
  private baseUrl = process.env.WHISPER_SERVICE_URL || 'http://localhost:3001';
  
  async transcribe(file: File): Promise<TranscriptionResult> {
    const formData = new FormData();
    formData.append('audio', file);
    
    const response = await fetch(`${this.baseUrl}/api/transcribe-upload`, {
      method: 'POST',
      body: formData,
    });
    
    if (!response.ok) throw new Error('Transcription failed');
    return response.json();
  }
}
```

### Monorepo con Turborepo

```json
// turbo.json
{
  "pipeline": {
    "dev": {
      "dependsOn": ["^build"],
      "cache": false
    },
    "whisper-service#dev": {
      "dependsOn": ["@whisper/service#check-deps"],
      "outputs": []
    }
  }
}
```

### Docker Compose para producciÃ³n

```yaml
version: '3.8'

services:
  whisper:
    build: ./services/whisper
    restart: unless-stopped
    ports:
      - "3001:3001"
    volumes:
      - whisper-models:/app/models
      - whisper-uploads:/app/uploads
    environment:
      - NODE_ENV=production
      - WHISPER_MODEL=base
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  whisper-models:
  whisper-uploads:
```

## ğŸ”® Roadmap: Modos HÃ­bridos de Respuesta

### PrÃ³ximamente en v2.0

#### ğŸŒŠ **Streaming Mode**
TranscripciÃ³n en tiempo real con WebSockets
```javascript
// Futuro API
const stream = whisper.streamTranscribe(audioStream);
stream.on('partial', (text) => console.log('Parcial:', text));
stream.on('final', (text) => console.log('Final:', text));
```

#### ğŸ”„ **Webhook Mode**
Procesamiento asÃ­ncrono con callbacks
```javascript
// Futuro API
await whisper.transcribeAsync(file, {
  webhookUrl: 'https://tu-app.com/webhook/transcription',
  webhookHeaders: { 'X-API-Key': 'secret' }
});
```

#### ğŸ¯ **Queue Mode**
IntegraciÃ³n con sistemas de colas (RabbitMQ, Redis)
```javascript
// Futuro API
await whisper.queueTranscription(file, {
  queue: 'transcriptions',
  priority: 'high'
});
```

#### ğŸ¤– **Hybrid AI Mode**
CombinaciÃ³n de Whisper local + APIs cloud para optimizaciÃ³n
```javascript
// Futuro API
await whisper.transcribeHybrid(file, {
  localFirst: true,
  fallbackToCloud: true,
  providers: ['whisper-local', 'openai', 'google']
});
```

## ğŸŒ FilosofÃ­a: Integrable por DiseÃ±o

Este microservicio estÃ¡ construido con una filosofÃ­a clara: **ser integrable en cualquier lugar**. No es solo un servidor de transcripciÃ³n, es un componente diseÃ±ado para adaptarse a tu arquitectura, no al revÃ©s.

### ğŸ”Œ IntegraciÃ³n Universal

- **Arquitectura AgnÃ³stica**: Funciona igual de bien con Next.js, Vue, Angular, React Native, Flutter o vanilla JavaScript
- **Protocol Flexible**: REST hoy, GraphQL maÃ±ana, gRPC cuando lo necesites
- **Deployment Anywhere**: Desde tu laptop hasta Kubernetes, pasando por Vercel, Railway o tu Raspberry Pi
- **Offline First**: DiseÃ±ado para funcionar sin internet, perfecto para aplicaciones edge

### ğŸ“± Offline & Edge Computing (PrÃ³ximamente)

```javascript
// Futuro: Modo offline para aplicaciones mÃ³viles
const whisper = new WhisperOffline({
  modelPath: './models/whisper-tiny.onnx',
  runtime: 'webassembly' // o 'tensorflow-lite'
});

// TranscripciÃ³n 100% local en el dispositivo
const result = await whisper.transcribeOffline(audioBlob);
```

### ğŸ”„ Multi-Engine Support (Roadmap v3.0)

El futuro es multi-motor. PodrÃ¡s elegir el backend que mejor se adapte a tu caso de uso:

```javascript
// ConfiguraciÃ³n futura multi-engine
const whisperService = new WhisperService({
  engines: [
    {
      name: 'whisper-cpp',
      priority: 1,
      platforms: ['server', 'desktop']
    },
    {
      name: 'transformers-js',
      priority: 2,
      platforms: ['browser', 'mobile']
    },
    {
      name: 'huggingface-api',
      priority: 3,
      platforms: ['all'],
      requiresInternet: true
    }
  ],
  fallbackStrategy: 'next-available'
});
```

### ğŸŒŸ Casos de Uso Futuros

- **PWAs Offline**: TranscripciÃ³n sin conexiÃ³n en Progressive Web Apps
- **React Native**: SDK nativo para apps mÃ³viles
- **Electron Apps**: IntegraciÃ³n directa para aplicaciones desktop
- **IoT Devices**: VersiÃ³n ligera para dispositivos embebidos
- **Browser Extension**: TranscripciÃ³n directa en el navegador
- **CLI Tool**: Herramienta de lÃ­nea de comandos global

## ğŸ“Š Benchmarks

| Modelo | Velocidad | PrecisiÃ³n | RAM | Caso de uso |
|--------|-----------|-----------|-----|--------------|
| tiny   | 10x       | â˜…â˜…â˜†â˜†â˜†     | 1GB | Prototipos |
| base   | 7x        | â˜…â˜…â˜…â˜†â˜†     | 1GB | Desarrollo |
| small  | 4x        | â˜…â˜…â˜…â˜…â˜†     | 2GB | ProducciÃ³n |
| medium | 2x        | â˜…â˜…â˜…â˜…â˜…     | 5GB | Alta precisiÃ³n |

## ğŸ› ï¸ ConfiguraciÃ³n Avanzada

### Variables de entorno

```bash
# .env
PORT=3001
WHISPER_MODEL=base
MAX_FILE_SIZE=100MB
ENABLE_CORS=true
LOG_LEVEL=info
```

### ConfiguraciÃ³n de modelos

```javascript
// config/whisper.config.js
module.exports = {
  model: process.env.WHISPER_MODEL || 'base',
  language: 'auto',
  threads: 4,
  processors: 1,
  translate: false,
  timestamps: true
};
```

## ğŸ” Seguridad

- âœ… ValidaciÃ³n de tipos de archivo
- âœ… LÃ­mites de tamaÃ±o configurables
- âœ… SanitizaciÃ³n de nombres de archivo
- âœ… CORS configurable
- âœ… Rate limiting ready

## ğŸ“¦ Despliegue

### Railway/Render
```bash
# railway.json
{
  "build": {
    "builder": "NIXPACKS",
    "buildCommand": "npm run setup"
  },
  "deploy": {
    "startCommand": "npm start",
    "healthcheckPath": "/api/health"
  }
}
```

### Kubernetes
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: whisper-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: whisper
  template:
    metadata:
      labels:
        app: whisper
    spec:
      containers:
      - name: whisper
        image: whisper-service:latest
        ports:
        - containerPort: 3001
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
```

## ğŸš€ Por quÃ© Open Source

Este proyecto es **100% open source** porque creemos que la tecnologÃ­a de transcripciÃ³n debe ser accesible para todos. Al ser cÃ³digo abierto:

- **Transparencia Total**: Sabes exactamente quÃ© hace tu servicio de transcripciÃ³n
- **Sin Vendor Lock-in**: No dependes de APIs propietarias o servicios de pago
- **Comunidad Activa**: Miles de desarrolladores mejorando el cÃ³digo
- **Adaptable**: ModifÃ­calo para tus necesidades especÃ­ficas
- **Gratis para Siempre**: Sin sorpresas, sin lÃ­mites artificiales

### ğŸŒ± EvoluciÃ³n Continua

Este microservicio estÃ¡ diseÃ±ado para crecer y adaptarse:

1. **Hoy**: REST API con Whisper C++
2. **MaÃ±ana**: WebSockets, GraphQL, gRPC
3. **Futuro**: WebAssembly, Edge Computing, AI distribuida

## ğŸ¤ Contribuir

Este microservicio estÃ¡ diseÃ±ado para ser extendido. Algunas Ã¡reas donde puedes contribuir:

- ğŸŒ Soporte para mÃ¡s idiomas
- ğŸ”Œ Adaptadores para mÃ¡s frameworks
- ğŸ“Š MÃ©tricas y observabilidad
- ğŸ§ª MÃ¡s tests automatizados
- ğŸ“š DocumentaciÃ³n y ejemplos
- ğŸ”§ Optimizaciones de rendimiento
- ğŸŒ Modo offline para navegadores
- ğŸ“± SDKs para plataformas mÃ³viles

## ğŸ“œ Licencia

MIT License - Ãšsalo como quieras, donde quieras.

## ğŸ™ Agradecimientos

- OpenAI Whisper - Por el modelo de transcripciÃ³n
- nodejs-whisper - Por la integraciÃ³n con Node.js
- La comunidad open source - Por hacer esto posible

---

<div align="center">
  <p>Hecho con â¤ï¸ para la comunidad de desarrolladores</p>
  <p>Â¿Te gusta? â­ Dale una estrella!</p>
</div>
/**
 * DIARIZATION SERVICE - BAZAR MODE
 * 
 * REGLAS:
 * - TODO c√≥digo abierto, auditable, modificable
 * - TODO threshold configurable y documentado
 * - TODO embedding exportable y reemplazable
 * - TODO decisi√≥n registrada p√∫blicamente
 * - NO cajas negras, NO h√©roes individuales
 * 
 * XENOVA PYANNOTE INTEGRATION
 * Modelo: onnx-community/pyannote-segmentation-3.0
 * Whisper: onnx-community/whisper-base_timestamped
 */

import { pipeline } from '@xenova/transformers';

// PUBLIC CONFIGURATION - EDITABLE BY ANYONE
export const DIARIZATION_CONFIG = {
  // Modelo principal - CAMBIAR AQU√ç PARA USAR OTRO MODELO
  segmentationModel: 'Xenova/pyannote-segmentation',
  whisperModel: 'Xenova/whisper-base',
  
  // Umbrales - EXPUESTOS Y DOCUMENTADOS
  thresholds: {
    speakerChange: 0.7,    // Umbral para cambio de hablante
    minimumSegment: 1.0,   // Duraci√≥n m√≠nima de segmento (segundos)
    overlapTolerance: 0.2  // Tolerancia de solapamiento entre hablantes
  },
  
  // Colores y avatares - ESQUEMAS P√öBLICOS
  speakers: {
    DOCTOR: {
      color: '#3B82F6',      // Azul m√©dico
      avatar: 'üë®‚Äç‚öïÔ∏è',
      label: 'Doctor',
      defaultName: 'Dr. Smith'
    },
    PATIENT: {
      color: '#10B981',      // Verde paciente
      avatar: 'üë§',
      label: 'Paciente',
      defaultName: 'Paciente'
    },
    UNKNOWN: {
      color: '#6B7280',      // Gris desconocido
      avatar: '‚ùì',
      label: 'Desconocido',
      defaultName: 'Hablante'
    }
  },
  
  // Cache - L√ìGICA EXPUESTA Y CONFIGURABLE
  cache: {
    enabled: true,
    maxSize: 100,          // M√°ximo embeddings en cache
    ttl: 24 * 60 * 60 * 1000  // TTL en millisegundos (24h)
  }
};

// TIPOS P√öBLICOS - EXPORTABLES Y REUTILIZABLES
export interface DiarizationSegment {
  speaker: 'DOCTOR' | 'PATIENT' | 'UNKNOWN';
  startTime: number;
  endTime: number;
  text: string;
  confidence: number;
  chunks: Array<{
    text: string;
    timestamp: [number, number];
    confidence?: number;
  }>;
}

export interface DiarizationResult {
  segments: DiarizationSegment[];
  speakers: string[];
  processingTime: number;
  model: string;
  config: typeof DIARIZATION_CONFIG;
}

// EMBEDDINGS CACHE - AUDITABLE Y EXPORTABLE
class EmbeddingsCache {
  private cache: Map<string, any> = new Map();
  private timestamps: Map<string, number> = new Map();
  
  // M√âTODO P√öBLICO - CUALQUIER DEV PUEDE INSPECCIONAR
  public get(key: string): any | null {
    const timestamp = this.timestamps.get(key);
    if (!timestamp) return null;
    
    // Verificar TTL
    if (Date.now() - timestamp > DIARIZATION_CONFIG.cache.ttl) {
      this.cache.delete(key);
      this.timestamps.delete(key);
      return null;
    }
    
    return this.cache.get(key) || null;
  }
  
  // M√âTODO P√öBLICO - TOTALMENTE TRANSPARENTE
  public set(key: string, value: any): void {
    // Limpiar cache si excede el tama√±o m√°ximo
    if (this.cache.size >= DIARIZATION_CONFIG.cache.maxSize) {
      const oldestKey = this.cache.keys().next().value;
      this.cache.delete(oldestKey);
      this.timestamps.delete(oldestKey);
    }
    
    this.cache.set(key, value);
    this.timestamps.set(key, Date.now());
  }
  
  // M√âTODO P√öBLICO - EXPORTAR DATOS PARA AUDITOR√çA
  public export(): { embeddings: any[], metadata: any } {
    return {
      embeddings: Array.from(this.cache.entries()),
      metadata: {
        size: this.cache.size,
        maxSize: DIARIZATION_CONFIG.cache.maxSize,
        ttl: DIARIZATION_CONFIG.cache.ttl,
        timestamps: Array.from(this.timestamps.entries())
      }
    };
  }
  
  // M√âTODO P√öBLICO - LIMPIAR CACHE MANUALMENTE
  public clear(): void {
    this.cache.clear();
    this.timestamps.clear();
  }
}

// INSTANCIA GLOBAL - ACCESIBLE DESDE CUALQUIER LUGAR
const embeddingsCache = new EmbeddingsCache();

// SERVICIO PRINCIPAL - MODULAR Y AUDITABLE
export class DiarizationService {
  private segmentationPipeline: any = null;
  private whisperPipeline: any = null;
  private initialized = false;
  
  // M√âTODO P√öBLICO - INICIALIZACI√ìN TRANSPARENTE
  public async initialize(): Promise<void> {
    if (this.initialized) return;
    
    console.log('[DiarizationService] Initializing with config:', DIARIZATION_CONFIG);
    
    try {
      // Cargar pipeline de segmentaci√≥n
      this.segmentationPipeline = await pipeline(
        'feature-extraction',
        DIARIZATION_CONFIG.segmentationModel
      );
      
      // Cargar pipeline de Whisper con timestamps
      this.whisperPipeline = await pipeline(
        'automatic-speech-recognition',
        DIARIZATION_CONFIG.whisperModel
      );
      
      this.initialized = true;
      console.log('[DiarizationService] Initialized successfully');
    } catch (error) {
      console.error('[DiarizationService] Initialization failed:', error);
      throw error;
    }
  }
  
  // M√âTODO P√öBLICO - DIARIZACI√ìN PRINCIPAL
  public async diarizeAudio(audioData: Float32Array): Promise<DiarizationResult> {
    if (!this.initialized) {
      await this.initialize();
    }
    
    const startTime = Date.now();
    
    try {
      // 1. TRANSCRIPCI√ìN CON TIMESTAMPS
      const transcriptionResult = await this.whisperPipeline(audioData, {
        return_timestamps: 'word',
        language: 'es',
        task: 'transcribe'
      });
      
      // 2. SEGMENTACI√ìN DE HABLANTES
      const segments = await this.segmentSpeakers(audioData, transcriptionResult.chunks);
      
      // 3. POSTPROCESAMIENTO
      const diarizedSegments = this.postProcessSegments(segments, transcriptionResult.chunks);
      
      const result: DiarizationResult = {
        segments: diarizedSegments,
        speakers: this.extractSpeakers(diarizedSegments),
        processingTime: Date.now() - startTime,
        model: DIARIZATION_CONFIG.segmentationModel,
        config: DIARIZATION_CONFIG
      };
      
      console.log('[DiarizationService] Diarization completed:', result);
      return result;
      
    } catch (error) {
      console.error('[DiarizationService] Diarization failed:', error);
      throw error;
    }
  }
  
  // M√âTODO P√öBLICO - SEGMENTACI√ìN DE HABLANTES
  private async segmentSpeakers(audioData: Float32Array, chunks: any[]): Promise<any[]> {
    const cacheKey = this.generateCacheKey(audioData);
    
    // Verificar cache
    let embeddings = embeddingsCache.get(cacheKey);
    if (!embeddings) {
      // Generar embeddings
      embeddings = await this.segmentationPipeline(audioData);
      embeddingsCache.set(cacheKey, embeddings);
    }
    
    // Algoritmo de segmentaci√≥n - COMPLETAMENTE AUDITABLE
    const segments = [];
    let currentSpeaker = 'UNKNOWN';
    let segmentStart = 0;
    
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      const timestamp = chunk.timestamp;
      
      // Calcular probabilidad de cambio de hablante
      const changeProb = this.calculateSpeakerChangeProb(embeddings, timestamp);
      
      // Aplicar umbral P√öBLICO y CONFIGURABLE
      if (changeProb > DIARIZATION_CONFIG.thresholds.speakerChange) {
        // Guardar segmento anterior
        if (i > 0) {
          segments.push({
            speaker: currentSpeaker,
            start: segmentStart,
            end: timestamp[0],
            changeProb: changeProb
          });
        }
        
        // Nuevo segmento
        currentSpeaker = this.identifySpeaker(embeddings, timestamp);
        segmentStart = timestamp[0];
      }
    }
    
    // √öltimo segmento
    if (chunks.length > 0) {
      segments.push({
        speaker: currentSpeaker,
        start: segmentStart,
        end: chunks[chunks.length - 1].timestamp[1],
        changeProb: 0
      });
    }
    
    return segments;
  }
  
  // M√âTODO P√öBLICO - C√ÅLCULO DE PROBABILIDAD (AUDITABLE)
  private calculateSpeakerChangeProb(embeddings: any, timestamp: [number, number]): number {
    // Enhanced speaker change detection using embeddings variance
    if (!embeddings || !embeddings.data) return 0;
    
    const timePoint = timestamp[0];
    const frameIndex = Math.floor(timePoint * 100); // Assuming 100Hz embedding rate
    
    if (frameIndex < 1 || frameIndex >= embeddings.data.length) return 0;
    
    // Calculate cosine similarity between consecutive frames
    const currentFrame = embeddings.data[frameIndex];
    const previousFrame = embeddings.data[frameIndex - 1];
    
    if (!currentFrame || !previousFrame) return 0;
    
    let dotProduct = 0;
    let normA = 0;
    let normB = 0;
    
    for (let i = 0; i < currentFrame.length; i++) {
      dotProduct += currentFrame[i] * previousFrame[i];
      normA += currentFrame[i] * currentFrame[i];
      normB += previousFrame[i] * previousFrame[i];
    }
    
    const similarity = dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
    // Convert similarity to change probability (inverse relationship)
    return 1 - Math.max(0, Math.min(1, similarity));
  }
  
  // M√âTODO P√öBLICO - IDENTIFICACI√ìN DE HABLANTE
  private identifySpeaker(embeddings: any, timestamp: [number, number]): 'DOCTOR' | 'PATIENT' | 'UNKNOWN' {
    // Enhanced speaker identification using embedding clustering
    if (!embeddings || !embeddings.data) return 'UNKNOWN';
    
    const timePoint = timestamp[0];
    const frameIndex = Math.floor(timePoint * 100);
    
    if (frameIndex < 0 || frameIndex >= embeddings.data.length) return 'UNKNOWN';
    
    const currentEmbedding = embeddings.data[frameIndex];
    if (!currentEmbedding) return 'UNKNOWN';
    
    // Simple k-means style clustering
    // In a real implementation, this would use pre-computed speaker centroids
    const embeddingMagnitude = currentEmbedding.reduce((sum: number, val: number) => sum + Math.abs(val), 0);
    
    // Heuristic: Higher energy embeddings tend to be doctor (more assertive speech)
    // Lower energy tends to be patient (more hesitant)
    // This is a simplified approach - real implementation would use proper clustering
    if (embeddingMagnitude > 50) {
      return 'DOCTOR';
    } else if (embeddingMagnitude > 20) {
      return 'PATIENT';
    }
    
    return 'UNKNOWN';
  }
  
  // M√âTODO P√öBLICO - POSTPROCESAMIENTO
  private postProcessSegments(segments: any[], chunks: any[]): DiarizationSegment[] {
    const result: DiarizationSegment[] = [];
    
    for (const segment of segments) {
      // Filtrar chunks que pertenecen a este segmento
      const segmentChunks = chunks.filter(chunk => 
        chunk.timestamp[0] >= segment.start && chunk.timestamp[1] <= segment.end
      );
      
      if (segmentChunks.length === 0) continue;
      
      // Construir texto del segmento
      const text = segmentChunks.map(chunk => chunk.text).join('');
      
      // Calcular confidence promedio
      const confidence = segmentChunks.reduce((sum, chunk) => sum + (chunk.confidence || 0.8), 0) / segmentChunks.length;
      
      result.push({
        speaker: segment.speaker,
        startTime: segment.start,
        endTime: segment.end,
        text: text.trim(),
        confidence,
        chunks: segmentChunks.map(chunk => ({
          text: chunk.text,
          timestamp: chunk.timestamp,
          confidence: chunk.confidence
        }))
      });
    }
    
    return result;
  }
  
  // M√âTODO P√öBLICO - EXTRAER HABLANTES
  private extractSpeakers(segments: DiarizationSegment[]): string[] {
    const speakers = new Set<string>();
    segments.forEach(segment => speakers.add(segment.speaker));
    return Array.from(speakers);
  }
  
  // M√âTODO P√öBLICO - GENERAR CLAVE DE CACHE
  private generateCacheKey(audioData: Float32Array): string {
    // Hash simple basado en longitud y algunos samples
    const length = audioData.length;
    const sample1 = audioData[Math.floor(length * 0.25)] || 0;
    const sample2 = audioData[Math.floor(length * 0.75)] || 0;
    return `audio_${length}_${sample1.toFixed(4)}_${sample2.toFixed(4)}`;
  }
  
  // M√âTODO P√öBLICO - EXPORTAR CACHE PARA AUDITOR√çA
  public exportCache(): any {
    return embeddingsCache.export();
  }
  
  // M√âTODO P√öBLICO - LIMPIAR CACHE
  public clearCache(): void {
    embeddingsCache.clear();
  }
}

// INSTANCIA SINGLETON - PERO ACCESIBLE GLOBALMENTE
export const diarizationService = new DiarizationService();

// UTILIDADES P√öBLICAS - REUTILIZABLES
export class DiarizationUtils {
  // M√âTODO P√öBLICO - FUSIONAR TRANSCRIPCIONES
  public static mergeTranscriptions(whisperText: string, webSpeechText: string): string {
    // ALGORITMO SIMPLE Y AUDITABLE
    const whisperWords = whisperText.split(' ');
    const webSpeechWords = webSpeechText.split(' ');
    
    // Usar la transcripci√≥n m√°s larga como base
    const baseWords = whisperWords.length > webSpeechWords.length ? whisperWords : webSpeechWords;
    const altWords = whisperWords.length > webSpeechWords.length ? webSpeechWords : whisperWords;
    
    const merged: string[] = [];
    
    for (let i = 0; i < baseWords.length; i++) {
      const baseWord = baseWords[i];
      const altWord = altWords[i];
      
      if (altWord && this.wordSimilarity(baseWord, altWord) > 0.7) {
        // Usar la palabra m√°s larga si son similares
        merged.push(baseWord.length > altWord.length ? baseWord : altWord);
      } else {
        merged.push(baseWord);
      }
    }
    
    return merged.join(' ');
  }
  
  // M√âTODO P√öBLICO - SIMILITUD DE PALABRAS
  private static wordSimilarity(word1: string, word2: string): number {
    const a = word1.toLowerCase();
    const b = word2.toLowerCase();
    
    if (a === b) return 1.0;
    
    // Distancia de Levenshtein normalizada
    const distance = this.levenshteinDistance(a, b);
    const maxLength = Math.max(a.length, b.length);
    
    return 1 - (distance / maxLength);
  }
  
  // M√âTODO P√öBLICO - DISTANCIA DE LEVENSHTEIN
  private static levenshteinDistance(a: string, b: string): number {
    const matrix = [];
    
    for (let i = 0; i <= b.length; i++) {
      matrix[i] = [i];
    }
    
    for (let j = 0; j <= a.length; j++) {
      matrix[0][j] = j;
    }
    
    for (let i = 1; i <= b.length; i++) {
      for (let j = 1; j <= a.length; j++) {
        if (b.charAt(i - 1) === a.charAt(j - 1)) {
          matrix[i][j] = matrix[i - 1][j - 1];
        } else {
          matrix[i][j] = Math.min(
            matrix[i - 1][j - 1] + 1,
            matrix[i][j - 1] + 1,
            matrix[i - 1][j] + 1
          );
        }
      }
    }
    
    return matrix[b.length][a.length];
  }
}

// DOCUMENTACI√ìN P√öBLICA - SIEMPRE ACTUALIZADA
export const DIARIZATION_DOCS = {
  version: '1.0.0',
  lastUpdated: new Date().toISOString(),
  description: 'Servicio de diarizaci√≥n modular y auditable usando Xenova/pyannote',
  
  configuration: {
    file: 'src/domains/medical-ai/services/DiarizationService.ts',
    configObject: 'DIARIZATION_CONFIG',
    editable: 'S√≠ - cualquier desarrollador puede modificar',
    thresholds: 'Todos los umbrales son p√∫blicos y configurables'
  },
  
  api: {
    initialize: 'Inicializar modelos de diarizaci√≥n',
    diarizeAudio: 'Procesar audio y generar segmentos por hablante',
    exportCache: 'Exportar cache de embeddings para auditor√≠a',
    clearCache: 'Limpiar cache manualmente'
  },
  
  decisions: [
    'Modelo pyannote-segmentation-3.0 elegido por mejor balance precisi√≥n/velocidad',
    'Cache de embeddings para evitar reprocesamiento',
    'Umbrales configurables para diferentes escenarios m√©dicos',
    'Algoritmo de fusi√≥n simple pero auditable'
  ],
  
  risks: [
    'Privacidad: embeddings contienen informaci√≥n de voz',
    'Precisi√≥n: algoritmos simples pueden fallar en casos complejos',
    'Rendimiento: modelos grandes pueden ser lentos en dispositivos limitados'
  ],
  
  contribute: {
    issues: 'Reportar problemas en GitHub Issues',
    pullRequests: 'PRs bienvenidos para mejoras',
    documentation: 'Documentaci√≥n debe actualizarse con cada cambio'
  }
};
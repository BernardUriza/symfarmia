/**
 * üéôÔ∏è Endpoint de Transcripci√≥n - Proxy a SusurroTest
 * Maneja audio desde frontend, procesa y env√≠a a microservicio
 */

import { NextRequest, NextResponse } from 'next/server';
import { writeFile, unlink, readFile } from 'fs/promises';
import { spawn } from 'child_process';
import path from 'path';
import { tmpdir } from 'os';
import susurroConfig from '../../../microservice.config.js';

// Configuraci√≥n del microservicio desde archivo centralizado
const SUSURRO_CONFIG = {
  baseUrl: process.env.SUSURRO_SERVICE_URL || susurroConfig.integration.envVars.SUSURRO_SERVICE_URL,
  endpoint: susurroConfig.microservice.transcription,
  timeout: parseInt(susurroConfig.integration.envVars.TRANSCRIPTION_TIMEOUT) || 30000,
  maxFileSize: parseInt(susurroConfig.integration.envVars.MAX_FILE_SIZE) || 50000000,
  allowedTypes: ['audio/wav', 'audio/webm', 'audio/webm;codecs=opus', 'audio/mp3', 'audio/m4a']
};

export async function POST(request: NextRequest) {
  const startTime = Date.now();
  
  try {
    // üìù Logs con emojis (mantener estilo existente)
    console.log('üéôÔ∏è [Transcription API] Iniciando procesamiento...');
    
    // üåê Detectar entorno
    const isNetlify = process.env.NETLIFY === 'true';
    const isDevelopment = process.env.NODE_ENV === 'development';
    const isProduction = process.env.NODE_ENV === 'production';
    
    console.log(`üåç [Transcription API] Entorno: Netlify=${isNetlify}, Production=${isProduction}, Development=${isDevelopment}`);
    
    // üìã Validar Content-Type
    const contentType = request.headers.get('content-type');
    if (!contentType?.includes('multipart/form-data')) {
      return NextResponse.json(
        { success: false, error: 'üö´ Content-Type debe ser multipart/form-data' },
        { status: 400 }
      );
    }

    // üìÅ Extraer archivo del FormData
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;
    
    if (!audioFile) {
      console.log('‚ùå [Transcription API] No se encontr√≥ archivo de audio');
      return NextResponse.json(
        { success: false, error: 'üé§ No se encontr√≥ archivo de audio' },
        { status: 400 }
      );
    }

    // üîç Validaciones de archivo
    if (audioFile.size > SUSURRO_CONFIG.maxFileSize) {
      return NextResponse.json(
        { success: false, error: `üìè Archivo muy grande. M√°ximo: ${SUSURRO_CONFIG.maxFileSize / 1024 / 1024}MB` },
        { status: 413 }
      );
    }

    console.log(`üéµ [Transcription API] Archivo recibido: ${audioFile.name} (${audioFile.size} bytes)`);

    // üöÄ Si estamos en Netlify, esta ruta no deber√≠a ejecutarse debido al redirect
    // Pero si por alguna raz√≥n llega aqu√≠, devolver un error informativo
    if (isNetlify && !isDevelopment) {
      console.log('‚ö†Ô∏è [Transcription API] Esta ruta no deber√≠a ejecutarse en Netlify');
      console.log('üîÑ [Transcription API] El redirect en netlify.toml deber√≠a manejar esta petici√≥n');
      
      // Devolver informaci√≥n de debug
      return NextResponse.json({
        error: 'Esta ruta deber√≠a ser manejada por Netlify redirect',
        debug: {
          message: 'Verifica que el redirect en netlify.toml est√© funcionando correctamente',
          expected_redirect: '/api/transcription -> /.netlify/functions/transcribe-upload',
          environment: {
            NODE_ENV: process.env.NODE_ENV,
            NETLIFY: process.env.NETLIFY
          }
        }
      }, { status: 503 });
    }

    // üè† En desarrollo o sin Netlify, usar microservicio local
    console.log('üè† [Transcription API] Usando microservicio local');

    // üîÑ Verificar tipo de archivo y procesar si es necesario
    let processedFile = audioFile;
    const fileType = audioFile.type;
    const isWavFile = fileType === 'audio/wav' || fileType === 'audio/wave';
    
    // Si no es WAV, necesitamos convertir
    if (!isWavFile && fileType.startsWith('audio/')) {
      console.log(`üîÑ [Transcription API] Convirtiendo ${fileType} a WAV...`);
      try {
        processedFile = await convertToWAV(audioFile);
        console.log(`‚úÖ [Transcription API] Conversi√≥n exitosa`);
      } catch (convError) {
        console.log(`‚ö†Ô∏è [Transcription API] Error al convertir, usando archivo original:`, convError);
        // Intentar con el archivo original si la conversi√≥n falla
      }
    } else if (isWavFile) {
      console.log(`‚úÖ [Transcription API] Archivo ya es WAV`);
    } else {
      console.log(`‚ö†Ô∏è [Transcription API] Tipo no reconocido: ${fileType}`);
    }

    // üåê Preparar FormData para microservicio
    const susurroFormData = new FormData();
    susurroFormData.append('audio', processedFile);
    susurroFormData.append('language', 'es'); // Espa√±ol por defecto para contexto m√©dico

    // üì° Enviar a SusurroTest
    console.log('üì° [Transcription API] Enviando a SusurroTest...');
    
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), SUSURRO_CONFIG.timeout);

    const response = await fetch(`${SUSURRO_CONFIG.baseUrl}${SUSURRO_CONFIG.endpoint}`, {
      method: 'POST',
      body: susurroFormData,
      signal: controller.signal,
      headers: {
        // No incluir Content-Type, fetch lo manejar√° autom√°ticamente con FormData
      }
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      throw new Error(`SusurroTest error: ${response.status} ${response.statusText}`);
    }

    const result = await response.json();
    const processingTime = Date.now() - startTime;

    console.log(`‚úÖ [Transcription API] Completado en ${processingTime}ms`);
    console.log(`üìù [Transcription API] Transcripci√≥n: "${result.transcript}"`);

    // üì§ Respuesta unificada
    return NextResponse.json({
      success: true,
      transcript: result.transcript || '',
      confidence: result.confidence || 0,
      processing_time_ms: processingTime,
      source: 'susurro-microservice',
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    const processingTime = Date.now() - startTime;
    console.error(`‚ùå [Transcription API] Error despu√©s de ${processingTime}ms:`, error);

    // üîç Manejo espec√≠fico de errores
    let errorMessage = 'Error interno del servidor';
    let statusCode = 500;

    if (error instanceof Error) {
      if (error.name === 'AbortError') {
        errorMessage = '‚è±Ô∏è Timeout: El procesamiento tard√≥ demasiado';
        statusCode = 408;
      } else if (error.message.includes('SusurroTest')) {
        errorMessage = 'üî¥ Microservicio SusurroTest no disponible';
        statusCode = 503;
      } else if (error.message.includes('Netlify Function')) {
        errorMessage = '‚òÅÔ∏è Netlify Function no disponible';
        statusCode = 503;
      } else if (error.message.includes('fetch')) {
        errorMessage = 'üåê Error de conectividad';
        statusCode = 502;
      }
    }

    return NextResponse.json(
      { 
        success: false, 
        error: errorMessage,
        processing_time_ms: processingTime,
        timestamp: new Date().toISOString()
      },
      { status: statusCode }
    );
  }
}

// üîÑ Funci√≥n para convertir audio a WAV usando FFmpeg
async function convertToWAV(audioFile: File): Promise<File> {
  const tempDir = tmpdir();
  const inputPath = path.join(tempDir, `input-${Date.now()}-${audioFile.name}`);
  const outputPath = path.join(tempDir, `output-${Date.now()}.wav`);
  
  try {
    // Guardar archivo temporal
    const buffer = Buffer.from(await audioFile.arrayBuffer());
    await writeFile(inputPath, buffer);
    
    // Convertir usando FFmpeg
    await new Promise<void>((resolve, reject) => {
      const ffmpeg = spawn('ffmpeg', [
        '-i', inputPath,
        '-acodec', 'pcm_s16le',
        '-ac', '1',
        '-ar', '16000',
        '-y',
        outputPath
      ]);
      
      ffmpeg.on('error', (err) => {
        console.error('‚ùå [FFmpeg] Error al ejecutar:', err);
        reject(new Error('FFmpeg no disponible'));
      });
      
      ffmpeg.stderr.on('data', (data) => {
        console.log(`üîß [FFmpeg] ${data}`);
      });
      
      ffmpeg.on('close', (code) => {
        if (code !== 0) {
          reject(new Error(`FFmpeg exit√≥ con c√≥digo ${code}`));
        } else {
          resolve();
        }
      });
    });
    
    // Leer archivo convertido
    const wavBuffer = await readFile(outputPath);
    const wavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
    const wavFile = new File([wavBlob], 'audio.wav', { type: 'audio/wav' });
    
    // Limpiar archivos temporales
    await unlink(inputPath).catch(() => {});
    await unlink(outputPath).catch(() => {});
    
    return wavFile;
    
  } catch (error) {
    // Limpiar en caso de error
    await unlink(inputPath).catch(() => {});
    await unlink(outputPath).catch(() => {});
    throw error;
  }
}

export async function GET() {
  const isNetlify = process.env.NETLIFY === 'true';
  const isDevelopment = process.env.NODE_ENV === 'development';
  
  return NextResponse.json({
    message: 'üéôÔ∏è Transcription API - Endpoint para procesamiento de audio',
    methods: ['POST'],
    maxFileSize: `${SUSURRO_CONFIG.maxFileSize / 1024 / 1024}MB`,
    allowedTypes: SUSURRO_CONFIG.allowedTypes,
    service: isNetlify && !isDevelopment 
      ? 'Netlify Functions (/.netlify/functions/transcribe-upload)' 
      : SUSURRO_CONFIG.baseUrl,
    environment: {
      NODE_ENV: process.env.NODE_ENV,
      NETLIFY: process.env.NETLIFY
    }
  });
}
import { useState, useCallback, useRef } from 'react';
import { convertToWav } from '@/utils/audioConverter';

interface UseAudioRecorderReturn {
  isRecording: boolean;
  isTranscribing: boolean;
  transcript: string;
  error: string | null;
  startRecording: () => Promise<void>;
  stopRecording: () => Promise<void>;
  clearTranscript: () => void;
}

export function useAudioRecorder(): UseAudioRecorderReturn {
  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);

  // Refs tipados correctamente
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const streamRef = useRef<MediaStream | null>(null);
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null);
  
  // LÃ­mite mÃ¡ximo de grabaciÃ³n (45 segundos)
  const MAX_RECORDING_TIME = 45000; // milisegundos

  const startRecording = useCallback(async () => {
    try {
      setError(null);
      console.log('ðŸŽ¤ Iniciando grabaciÃ³n de audio...');
      
      // Solicitar permisos de audio con configuraciÃ³n especÃ­fica
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,  // Whisper prefiere 16kHz
          channelCount: 1,    // Mono
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      console.log('âœ… Stream de audio obtenido');
      console.log('ðŸ“Š Audio tracks:', stream.getAudioTracks().length);
      
      if (stream.getAudioTracks().length > 0) {
        const track = stream.getAudioTracks()[0];
        console.log('ðŸ”Š ConfiguraciÃ³n del track:', {
          enabled: track.enabled,
          kind: track.kind,
          label: track.label,
          settings: track.getSettings()
        });
      }

      streamRef.current = stream;
      audioChunksRef.current = [];

      // Configurar MediaRecorder con formato especÃ­fico
      const mimeTypes = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/wav',
        'audio/mp4',
        'audio/ogg'
      ];

      let selectedMimeType = '';
      for (const mimeType of mimeTypes) {
        if (MediaRecorder.isTypeSupported(mimeType)) {
          selectedMimeType = mimeType;
          console.log('âœ… Usando MIME type:', mimeType);
          break;
        }
      }

      if (!selectedMimeType) {
        throw new Error('No hay formatos de audio soportados');
      }

      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: selectedMimeType,
        audioBitsPerSecond: 16000 // Bitrate bajo para reducir tamaÃ±o
      });

      mediaRecorderRef.current.ondataavailable = (event) => {
        console.log('ðŸ“¦ Chunk de audio recibido:', {
          size: event.data.size,
          type: event.data.type
        });
        
        if (event.data.size > 0 && audioChunksRef.current) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorderRef.current.onstop = async () => {
        console.log('ðŸ›‘ GrabaciÃ³n detenida, procesando audio...');
        setIsTranscribing(true);
        
        try {
          const chunks = audioChunksRef.current || [];
          console.log('ðŸ“Š Total chunks recolectados:', chunks.length);
          console.log('ðŸ“ TamaÃ±os de chunks:', chunks.map(c => c.size));
          
          if (chunks.length === 0) {
            throw new Error('No se grabÃ³ audio');
          }

          // Crear blob de audio
          const audioBlob = new Blob(chunks, { 
            type: selectedMimeType 
          });
          
          console.log('ðŸ”Š Audio blob creado:', {
            size: audioBlob.size,
            type: audioBlob.type
          });

          if (audioBlob.size === 0) {
            throw new Error('Audio grabado estÃ¡ vacÃ­o');
          }

          if (audioBlob.size < 1000) {
            console.warn('âš ï¸ Audio muy pequeÃ±o, puede no transcribirse bien');
          }

          // Convertir a WAV para mejor compatibilidad con Whisper
          let finalAudioBlob = audioBlob;
          let fileName = 'recording.webm';
          
          try {
            console.log('ðŸ”„ Convirtiendo audio a WAV...');
            finalAudioBlob = await convertToWav(audioBlob);
            fileName = 'recording.wav';
            console.log('âœ… Audio convertido a WAV exitosamente');
          } catch (conversionError) {
            console.warn('âš ï¸ No se pudo convertir a WAV, enviando formato original:', conversionError);
            // Continuar con el formato original si la conversiÃ³n falla
          }

          // Crear FormData para enviar
          const formData = new FormData();
          const audioFile = new File([finalAudioBlob], fileName, { 
            type: finalAudioBlob.type 
          });
          
          formData.append('audio', audioFile);
          formData.append('language', 'es');
          
          console.log('ðŸ“¤ Enviando a /api/transcribe...', {
            fileName: audioFile.name,
            fileSize: audioFile.size,
            fileType: audioFile.type
          });

          // Enviar al endpoint
          const response = await fetch('/api/transcribe', {
            method: 'POST',
            body: formData,
          });

          console.log('ðŸ“¥ Respuesta del servidor:', {
            status: response.status,
            statusText: response.statusText,
            headers: Object.fromEntries(response.headers.entries())
          });

          if (!response.ok) {
            const errorText = await response.text();
            console.error('âŒ Error del servidor:', errorText);
            throw new Error(`Server error: ${response.status} - ${errorText}`);
          }

          const result = await response.json();
          console.log('ðŸ“‹ Resultado de transcripciÃ³n:', result);

          if (result.success) {
            const transcribedText = result.data?.text || '';
            console.log('âœ… Texto transcrito:', transcribedText);
            setTranscript(transcribedText);
            
            if (!transcribedText) {
              console.warn('âš ï¸ TranscripciÃ³n exitosa pero texto vacÃ­o');
              setError('TranscripciÃ³n exitosa pero no se detectÃ³ texto. Intente hablar mÃ¡s alto o mÃ¡s claro.');
            }
          } else {
            throw new Error(result.error || 'TranscripciÃ³n fallÃ³');
          }
          
        } catch (err) {
          console.error('âŒ Error en transcripciÃ³n:', err);
          setError(err instanceof Error ? err.message : 'Error desconocido en transcripciÃ³n');
        } finally {
          setIsTranscribing(false);
          // Limpiar stream
          if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => {
              track.stop();
              console.log('ðŸ”‡ Track de audio detenido');
            });
            streamRef.current = null;
          }
        }
      };

      mediaRecorderRef.current.onerror = (event) => {
        console.error('âŒ Error en MediaRecorder:', event);
        setError('Error en la grabaciÃ³n de audio');
        setIsRecording(false);
        setIsTranscribing(false);
      };

      // Comenzar grabaciÃ³n con chunks de 1 segundo
      mediaRecorderRef.current.start(1000);
      setIsRecording(true);
      
      console.log('âœ… GrabaciÃ³n iniciada exitosamente');
      
      // Configurar timer para detener automÃ¡ticamente despuÃ©s del lÃ­mite
      recordingTimerRef.current = setTimeout(() => {
        console.log('â° LÃ­mite de tiempo alcanzado, deteniendo grabaciÃ³n...');
        setError('GrabaciÃ³n detenida: lÃ­mite de 45 segundos alcanzado');
        if (mediaRecorderRef.current) {
          mediaRecorderRef.current.stop();
          setIsRecording(false);
        }
      }, MAX_RECORDING_TIME);
      
    } catch (err) {
      console.error('âŒ Error iniciando grabaciÃ³n:', err);
      setError(err instanceof Error ? err.message : 'Error accediendo al micrÃ³fono');
      setIsRecording(false);
    }
  }, []);

  const stopRecording = useCallback(async () => {
    console.log('ðŸ›‘ Solicitando detener grabaciÃ³n...');
    
    // Limpiar el timer si existe
    if (recordingTimerRef.current) {
      clearTimeout(recordingTimerRef.current);
      recordingTimerRef.current = null;
      console.log('â±ï¸ Timer de grabaciÃ³n cancelado');
    }
    
    if (mediaRecorderRef.current && isRecording) {
      try {
        mediaRecorderRef.current.stop();
        setIsRecording(false);
        console.log('âœ… GrabaciÃ³n detenida');
      } catch (err) {
        console.error('âŒ Error deteniendo grabaciÃ³n:', err);
        setError('Error deteniendo la grabaciÃ³n');
      }
    } else {
      console.warn('âš ï¸ No hay grabaciÃ³n activa para detener');
    }
  }, [isRecording]);

  const clearTranscript = useCallback(() => {
    console.log('ðŸ§¹ Limpiando transcript');
    setTranscript('');
    setError(null);
  }, []);

  return {
    isRecording,
    isTranscribing,
    transcript,
    error,
    startRecording,
    stopRecording,
    clearTranscript,
  };
}
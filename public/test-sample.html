<!DOCTYPE html>
<html>
<head>
    <title>Test Sample Transcription</title>
    <meta charset="UTF-8">
</head>
<body>
    <h1>Testing YOUR useSimpleWhisperHybrid Implementation</h1>
    <button id="testBtn" onclick="runTest()">Run Test with sample.wav</button>
    <div id="status" style="margin: 20px 0; padding: 10px; background: #f0f0f0;"></div>
    <div id="result" style="margin: 20px 0; padding: 20px; background: #e8f5e9; display: none;">
        <h2>Transcription Result:</h2>
        <p id="transcriptionText" style="font-size: 1.5em; font-weight: bold;"></p>
    </div>
    <pre id="log" style="background: #333; color: #0f0; padding: 10px; height: 300px; overflow-y: auto;"></pre>

    <script type="module">
        window.log = function(msg) {
            const logEl = document.getElementById('log');
            const time = new Date().toLocaleTimeString();
            logEl.textContent += `[${time}] ${msg}\n`;
            logEl.scrollTop = logEl.scrollHeight;
        };

        window.runTest = async function() {
            const statusEl = document.getElementById('status');
            const resultEl = document.getElementById('result');
            const transcriptionEl = document.getElementById('transcriptionText');
            
            try {
                log('🚀 Starting test...');
                statusEl.textContent = 'Loading audio processing service...';
                
                // Import YOUR actual implementation
                const { loadWhisperModel, transcribeAudio } = await import('/src/domains/medical-ai/services/audioProcessingService.js');
                
                log('📦 Imported audioProcessingService');
                
                // Load model using YOUR implementation
                statusEl.textContent = 'Loading Whisper model...';
                await loadWhisperModel({
                    onProgress: (p) => {
                        if (p?.progress) {
                            statusEl.textContent = `Loading model: ${p.progress}%`;
                            log(`Model progress: ${p.progress}%`);
                        }
                    }
                });
                
                log('✅ Model loaded');
                
                // Load sample.wav
                statusEl.textContent = 'Loading sample.wav...';
                const response = await fetch('/test-audio/sample.wav');
                if (!response.ok) throw new Error('Failed to load sample.wav');
                
                const arrayBuffer = await response.arrayBuffer();
                log(`📁 Loaded WAV: ${(arrayBuffer.byteLength / 1024).toFixed(2)} KB`);
                
                // Decode audio
                statusEl.textContent = 'Decoding audio...';
                const audioContext = new AudioContext();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                const audioData = audioBuffer.getChannelData(0);
                
                log(`🎵 Audio decoded: ${audioBuffer.duration.toFixed(2)}s @ ${audioBuffer.sampleRate}Hz`);
                log(`📊 Samples: ${audioData.length}`);
                
                // Transcribe using YOUR implementation
                statusEl.textContent = 'Transcribing with YOUR audioProcessingService...';
                log('🎯 Calling transcribeAudio...');
                
                const result = await transcribeAudio(audioData, {
                    language: 'es',
                    task: 'transcribe'
                });
                
                log('✅ Transcription complete!');
                log(`📝 Result: ${JSON.stringify(result)}`);
                
                // Show result
                statusEl.textContent = '✅ Transcription successful!';
                resultEl.style.display = 'block';
                transcriptionEl.textContent = `"${result.text || '[No transcription detected]'}"`;
                
                // Log the actual transcription
                log(`\n🎉 TRANSCRIPTION: "${result.text}"\n`);
                
                if (result.text) {
                    console.log('🎯 AUDIO CONTENT:', result.text);
                    alert(`El audio dice: "${result.text}"`);
                }
                
            } catch (error) {
                statusEl.textContent = `❌ Error: ${error.message}`;
                log(`❌ ERROR: ${error.stack}`);
                console.error('Test failed:', error);
            }
        };

        // Auto-run on load
        window.addEventListener('load', () => {
            log('Page loaded. Click button to test.');
            log('This will use YOUR audioProcessingService implementation.');
        });
    </script>
</body>
</html>
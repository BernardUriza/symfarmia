<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Whisper Xenova Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        button {
            background-color: #007bff;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 4px;
            cursor: pointer;
            margin: 5px;
        }
        button:hover {
            background-color: #0056b3;
        }
        button:disabled {
            background-color: #6c757d;
            cursor: not-allowed;
        }
        .status {
            margin: 10px 0;
            padding: 10px;
            border-radius: 4px;
        }
        .success {
            background-color: #d4edda;
            color: #155724;
        }
        .error {
            background-color: #f8d7da;
            color: #721c24;
        }
        .info {
            background-color: #d1ecf1;
            color: #0c5460;
        }
        .warning {
            background-color: #fff3cd;
            color: #856404;
        }
        #output {
            white-space: pre-wrap;
            font-family: monospace;
            background-color: #f8f9fa;
            padding: 10px;
            border-radius: 4px;
            margin-top: 10px;
            max-height: 400px;
            overflow-y: auto;
        }
        .file-input-wrapper {
            margin: 20px 0;
        }
        .transcription-result {
            margin-top: 20px;
            padding: 15px;
            background-color: #e9ecef;
            border-radius: 4px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Whisper Xenova Test</h1>
        <p>Test de transcripción usando Xenova/whisper-base</p>

        <div class="file-input-wrapper">
            <input type="file" id="audioFile" accept="audio/*,.wav,.mp3,.m4a,.webm" />
            <button onclick="transcribeFile()" id="transcribeBtn">Transcribir Archivo</button>
        </div>

        <div>
            <button onclick="recordAudio()" id="recordBtn">🎤 Grabar Audio</button>
            <button onclick="stopRecording()" id="stopBtn" disabled>⏹️ Detener</button>
            <button onclick="loadModel()" id="loadBtn">📥 Cargar Modelo</button>
            <button onclick="testWorker()" id="workerBtn">🔧 Probar Worker</button>
        </div>

        <div id="status"></div>
        <div id="output"></div>
        <div id="transcription" class="transcription-result" style="display:none;">
            <h3>Transcripción:</h3>
            <p id="transcriptionText"></p>
        </div>
    </div>

    <script type="module">
        let pipeline = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let worker = null;

        // Status helper
        function setStatus(message, type = 'info') {
            const status = document.getElementById('status');
            status.className = `status ${type}`;
            status.textContent = message;
            addLog(`[${type.toUpperCase()}] ${message}`);
        }

        // Logging helper
        function addLog(message) {
            const output = document.getElementById('output');
            const timestamp = new Date().toLocaleTimeString();
            output.textContent += `[${timestamp}] ${message}\n`;
            output.scrollTop = output.scrollHeight;
        }

        // Load Whisper model
        window.loadModel = async function() {
            try {
                setStatus('Cargando modelo Whisper...', 'info');
                document.getElementById('loadBtn').disabled = true;

                // Import Transformers.js
                const { pipeline: createPipeline } = await import('https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2');
                
                addLog('Transformers.js importado correctamente');

                // Create pipeline
                pipeline = await createPipeline(
                    'automatic-speech-recognition',
                    'Xenova/whisper-base',
                    {
                        progress_callback: (progress) => {
                            if (progress.status === 'progress') {
                                const percent = Math.round(progress.progress);
                                setStatus(`Descargando modelo: ${percent}%`, 'info');
                            }
                        }
                    }
                );

                setStatus('Modelo cargado exitosamente', 'success');
                document.getElementById('transcribeBtn').disabled = false;
                addLog('Pipeline creado: ' + typeof pipeline);
            } catch (error) {
                setStatus(`Error cargando modelo: ${error.message}`, 'error');
                console.error(error);
            }
        };

        // Transcribe audio file
        window.transcribeFile = async function() {
            const fileInput = document.getElementById('audioFile');
            const file = fileInput.files[0];
            
            if (!file) {
                setStatus('Por favor selecciona un archivo de audio', 'warning');
                return;
            }

            if (!pipeline) {
                setStatus('Primero debes cargar el modelo', 'warning');
                return;
            }

            try {
                setStatus('Procesando archivo...', 'info');
                addLog(`Archivo: ${file.name}, Tamaño: ${(file.size / 1024).toFixed(2)} KB`);

                // Convert file to Float32Array
                const arrayBuffer = await file.arrayBuffer();
                const audioContext = new AudioContext();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                const float32Audio = audioBuffer.getChannelData(0);

                addLog(`Audio decodificado: ${audioBuffer.duration.toFixed(2)}s, ${audioBuffer.sampleRate}Hz`);
                setStatus('Transcribiendo audio...', 'info');

                const startTime = performance.now();
                
                // Transcribe
                const result = await pipeline(float32Audio, {
                    language: 'es',
                    task: 'transcribe',
                    chunk_length_s: 30,
                    stride_length_s: 5
                });

                const duration = ((performance.now() - startTime) / 1000).toFixed(2);
                
                setStatus(`Transcripción completada en ${duration}s`, 'success');
                showTranscription(result.text);
                addLog(`Transcripción: "${result.text}"`);

            } catch (error) {
                setStatus(`Error: ${error.message}`, 'error');
                console.error(error);
            }
        };

        // Record audio
        window.recordAudio = async function() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    addLog(`Audio grabado: ${(audioBlob.size / 1024).toFixed(2)} KB`);
                    
                    // Convert to file for transcription
                    const file = new File([audioBlob], 'recording.webm', { type: 'audio/webm' });
                    const dt = new DataTransfer();
                    dt.items.add(file);
                    document.getElementById('audioFile').files = dt.files;
                    
                    // Auto-transcribe
                    if (pipeline) {
                        await transcribeFile();
                    }
                };

                mediaRecorder.start();
                setStatus('Grabando...', 'info');
                document.getElementById('recordBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;

            } catch (error) {
                setStatus(`Error al acceder al micrófono: ${error.message}`, 'error');
            }
        };

        // Stop recording
        window.stopRecording = function() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                setStatus('Grabación detenida', 'info');
                document.getElementById('recordBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
            }
        };

        // Test worker
        window.testWorker = async function() {
            try {
                setStatus('Iniciando worker...', 'info');
                
                worker = new Worker('/workers/audioProcessingWorker.js');
                
                worker.onmessage = (event) => {
                    addLog(`Worker message: ${JSON.stringify(event.data)}`);
                    
                    if (event.data.type === 'MODEL_READY') {
                        setStatus('Worker listo', 'success');
                    } else if (event.data.type === 'MODEL_ERROR') {
                        setStatus(`Worker error: ${event.data.error}`, 'error');
                    }
                };

                worker.onerror = (error) => {
                    setStatus(`Worker error: ${error.message}`, 'error');
                };

                worker.postMessage({ type: 'INIT' });
                
            } catch (error) {
                setStatus(`Error iniciando worker: ${error.message}`, 'error');
            }
        };

        // Show transcription
        function showTranscription(text) {
            const transcriptionDiv = document.getElementById('transcription');
            const transcriptionText = document.getElementById('transcriptionText');
            transcriptionDiv.style.display = 'block';
            transcriptionText.textContent = text || '(Sin transcripción)';
        }

        // Auto-load model on page load
        window.addEventListener('load', () => {
            addLog('Página cargada, listo para comenzar');
            addLog('Usa el botón "Cargar Modelo" para iniciar');
        });
    </script>
</body>
</html>